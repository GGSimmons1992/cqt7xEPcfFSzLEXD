{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27950b1f-6ea5-4346-8e69-c5a1659ba6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#from os.path import exists\n",
    "import json\n",
    "#import scipy.stats as stats\n",
    "import math\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#import seaborn as sb\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.tree import DecisionTreeClassifier as tree\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from xgboost import XGBClassifier as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB as gnb\n",
    "#from sklearn.ensemble import VotingClassifier\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sm\n",
    "import pickle\n",
    "#from sklearn import preprocessing\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c463ddf-f64d-42a7-9fe5-e4ddca9ea2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveModelsBasedOnModelType(modelType):\n",
    "    if modelType == 'log':\n",
    "        gridmodel = lm.LogisticRegression(random_state=51)\n",
    "        finalmodel = lm.LogisticRegression(random_state=51)\n",
    "    elif modelType == 'naiveBayes':\n",
    "        gridmodel = gnb()\n",
    "        finalmodel = gnb()\n",
    "    elif modelType == 'tree':\n",
    "        gridmodel = tree(random_state=51)\n",
    "        finalmodel = tree(random_state=51)\n",
    "    elif modelType == 'forest':\n",
    "        gridmodel = rf(random_state=51)\n",
    "        finalmodel = rf(random_state=51)\n",
    "    elif modelType == 'knn':\n",
    "        gridmodel = knn()\n",
    "        finalmodel = knn()\n",
    "    elif modelType == 'xgboost':\n",
    "        gridmodel = xgb(random_state=51)\n",
    "        finalmodel = xgb(random_state=51)\n",
    "    elif modelType == 'svm':\n",
    "        gridmodel = SVC(random_state=51)\n",
    "        finalmodel = SVC(random_state=51)\n",
    "    else:\n",
    "        raise Exception(\"modelType Value not considered. Please choose from ['log','naiveBayes','tree','forest','knn','xgboost','svm']\")\n",
    "    return gridmodel,finalmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbec406-14ce-4276-a917-b63a05148515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModelWithGridSearch(searchParams,XTrain,yTrain,modelType):\n",
    "    gridmodel,finalmodel = retrieveModelsBasedOnModelType(modelType)\n",
    "    modelGridSearch = ms.GridSearchCV(gridmodel, param_grid=searchParams,scoring='f1')\n",
    "    modelGridSearch.fit(XTrain,yTrain)\n",
    "    finalmodel.set_params(**modelGridSearch.best_params_)\n",
    "    return finalmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c561b-5dfa-4d13-bab3-808d23d798bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTestData(testFileName):\n",
    "    df = pd.read_csv(f\"../Data/Interim/{testFileName}.csv\")\n",
    "    scaledDF = scaleTestData(df)\n",
    "    encodedDF = transformDF(scaledDF)\n",
    "    encodedDF.to_csv(f'../Data/Processed/{testFileName}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a7b623-4a26-4517-8949-fbad7bbd7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPredictData(predictFileName):\n",
    "    df = pd.read_csv(f\"../Data/External/{predictFileName}.csv\")\n",
    "    scaledDF = scaleTestData(df)\n",
    "    encodedDF = transformDF(scaledDF)\n",
    "    encodedDF.to_csv(f'../Data/External/{predictFileName}Final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a6617-9a69-4465-89a9-fd13da90ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(dataType,baseName):\n",
    "    TermDepositData = None\n",
    "    if dataType == \"train\":\n",
    "        TermDepositData = pd.read_csv(f\"../Data/Processed/{baseName}Train.csv\")\n",
    "    else:\n",
    "        TermDepositData = pd.read_csv(f\"../Data/Processed/{baseName}Test.csv\")\n",
    "    y = TermDepositData[[\"y\"]].values.ravel()\n",
    "    X = TermDepositData.drop(\"y\",axis=1)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addfb936-640c-4b30-80ff-0c0cdd0eeca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTreeFeatureRange(baseName):\n",
    "    fullName = baseName+'Under'\n",
    "    XTrainOriginal,yTrain = loadData(\"train\",fullName)\n",
    "    oheColumns = pickle.load(open(f'../Data/Interim/{fullName}OheColumns.pkl','rb'))\n",
    "    nTreeCols = XTrainOriginal.shape[1] - len(oheColumns)\n",
    "    midpoint = int((3+nTreeCols)/2)\n",
    "    return [3,midpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b768b47a-d79e-4b75-a95b-70cfe88db23a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def printScore(trueY,predictY,dataSetType):\n",
    "    scoreValue = sm.f1_score(trueY,predictY)\n",
    "    print(f\"{dataSetType} F1 score: {scoreValue}\")\n",
    "    return scoreValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22c343-1e0d-4418-acac-eda1e2e85802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model,modelName):\n",
    "    pickle.dump(model, open(f\"../Models/{modelName}.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d533b-5c0b-4b6b-8a6b-4cd861a3a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    baseName = \"TermDeposit\"\n",
    "    np.random.seed(51)\n",
    "    \n",
    "    treeFeatureRange = getTreeFeatureRange(baseName)\n",
    "    \n",
    "    logParams = {\n",
    "        \"l1_ratio\": [0,0.25,.5,0.75,1]\n",
    "    }\n",
    "    \n",
    "    bayesParams = {\n",
    "        \"var_smoothing\": [1,1e-3,1e-6,1e-9]\n",
    "    }\n",
    "    \n",
    "    treeParams = {\n",
    "        \"max_depth\":treeFeatureRange,\n",
    "        \"max_features\":treeFeatureRange,\n",
    "        \"ccp_alpha\":[0] + treeFeatureRange,\n",
    "        \"criterion\": [\"gini\",\"entropy\"]\n",
    "    }\n",
    "    forestParams = {\n",
    "        \"n_estimators\": [10,100,200],\n",
    "        \"max_depth\": treeFeatureRange,\n",
    "        \"max_features\": treeFeatureRange,\n",
    "        \"ccp_alpha\":[0] + treeFeatureRange,\n",
    "        \"criterion\": [\"gini\",\"entropy\"]\n",
    "    }\n",
    "    xgbParams = {\n",
    "        \"learning_rate\": [.1,.5,1],\n",
    "        \"n_estimators\": [10,100,200],\n",
    "        \"max_depth\": treeFeatureRange\n",
    "    }\n",
    "    svmParams = {\n",
    "        \"kernel\": [\"linear\",\"rbf\",\"poly\",\"sigmoid\"],\n",
    "        \"gamma\": [\"auto\",\"scale\"],\n",
    "        \"max_iter\": [100,500,1000]\n",
    "    }\n",
    "    goodModels = []\n",
    "    \n",
    "    categoricalColumns = pickle.load(open('../Data/Interim/TermDepositCategoricalCols.pkl','rb'))\n",
    "    \n",
    "    for balanceType in [\"Under\",\"Over\"]:\n",
    "        fullName = baseName + balanceType\n",
    "        oheColumns = pickle.load(open(f'../Data/Interim/{fullName}OheColumns.pkl','rb'))\n",
    "        \n",
    "        XTrainOriginal,yTrain = loadData(\"train\",fullName)\n",
    "        XTestOriginal,yTest = loadData(\"test\",fullName)\n",
    "        XTrainOHE = XTrainOriginal.drop(categoricalColumns,axis=1)\n",
    "        XTestOHE = XTestOriginal.drop(categoricalColumns,axis=1)\n",
    "        XTrainLE = XTrainOriginal.drop(oheColumns,axis=1)\n",
    "        XTestLE = XTestOriginal.drop(oheColumns,axis=1)\n",
    "        \n",
    "        nRows = XTrainOriginal.shape[0]\n",
    "        sqrtNRows = int(math.sqrt(nRows))\n",
    "        log2NRows = int(math.log2(nRows))\n",
    "        possibleThirdGeometricTerm1 = int((sqrtNRows ** 2)/log2NRows)\n",
    "        possibleThirdGeometricTerm2 = int((log2NRows ** 2)/sqrtNRows)\n",
    "        suggestedMaxKRange = [possibleThirdGeometricTerm1,possibleThirdGeometricTerm2]\n",
    "        kRange = [int(x) for x in np.linspace(5,max(suggestedMaxKRange),10)]\n",
    "    \n",
    "    \n",
    "        knnParams = {\n",
    "            \"n_neighbors\": kRange\n",
    "        }\n",
    "    \n",
    "        logModel = lm.LogisticRegression()\n",
    "        gnbModel = gnb()\n",
    "    \n",
    "        estimators = [\n",
    "            (\"logModel\",fitModelWithGridSearch(logParams,XTrainOHE,yTrain,'log'),'onehot'),\n",
    "            (\"naiveBayes\",fitModelWithGridSearch(bayesParams,XTrainOHE,yTrain,'naiveBayes'),'onehot'),\n",
    "            (\"tree\",fitModelWithGridSearch(treeParams,XTrainLE,yTrain,'tree'),'label'),\n",
    "            (\"forest\",fitModelWithGridSearch(forestParams,XTrainLE,yTrain,'forest'),'label'),\n",
    "            (\"knn\",fitModelWithGridSearch(knnParams,XTrainOHE,yTrain,'knn'),'onehot'),\n",
    "            (\"xgboost\",fitModelWithGridSearch(xgbParams,XTrainLE,yTrain,'xgboost'),'label'),\n",
    "            (\"svm\",fitModelWithGridSearch(svmParams,XTrainOHE,yTrain,'svm'),'onehot')\n",
    "        ]\n",
    "        \n",
    "        for est in estimators:\n",
    "            modName = f'{est[0]} {balanceType}sample'\n",
    "            mod = est[1]\n",
    "            if est[2] == 'onehot':\n",
    "                XTrain = XTrainOHE\n",
    "                XTest = XTestOHE\n",
    "            else:\n",
    "                XTrain = XTrainLE\n",
    "                XTest = XTestLE\n",
    "            mod.fit(XTrain,yTrain)\n",
    "            predictTrainY = mod.predict(XTrain)\n",
    "            predictTestY = mod.predict(XTest)\n",
    "            print(modName)\n",
    "            print(mod.get_params())\n",
    "            trainScore = printScore(yTrain,predictTrainY,\"Training\")\n",
    "            if printScore(yTest,predictTestY,\"Testing\") > 0.81:\n",
    "                saveModel(mod,modName)\n",
    "                goodModels.append(modName)\n",
    "\n",
    "    goodModelsDictionary = {\n",
    "        \"goodModels\": goodModels\n",
    "    }\n",
    "\n",
    "    with open('../Models/goodModelsDictionary.json', 'w') as fp:\n",
    "        json.dump(goodModelsDictionary, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced99521-da8b-4e36-9eeb-2b590e59a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73795e2-9b93-4585-ac98-a26ef95fc86d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
