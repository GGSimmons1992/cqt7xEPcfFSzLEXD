{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e5ee8-6ec3-43ee-be7d-be11fc050347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "from sklearn.feature_selection import chi2\n",
    "from scipy.stats import spearmanr\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler,NearMiss\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f32ceb-ab64-430a-96b8-53615c2b8f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeUnimportantCategoricalColumns(categoricalDF,y,combinedName,datasetType = 'train'):\n",
    "    if datasetType == 'test':\n",
    "        significantColumns = pickle.load(open(f\"../Data/Interim/{combinedName}SignificantCategoricalCols.pkl\", 'rb'))\n",
    "    else:\n",
    "        le = ce.OrdinalEncoder(return_df=True)\n",
    "        leDF = le.fit_transform(categoricalDF)\n",
    "        pValues = chi2(leDF, y)[1]\n",
    "        pValueDF = pd.DataFrame({\"feature\":list(categoricalDF.columns),\"pValue\":pValues},columns=[\"feature\",\"pValue\"],index=None)\n",
    "        lowPDF = pValueDF[pValueDF[\"pValue\"] < 0.05]\n",
    "        significantColumns = list(lowPDF['feature'])\n",
    "        pickle.dump(significantColumns, open(f\"../Data/Interim/{combinedName}SignificantCategoricalCols.pkl\", 'wb'))\n",
    "    return categoricalDF[significantColumns]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe558bea-6401-44ca-8310-3565ab7921d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeUnimportantNumericalColumns(numericalDF,y,combinedName,datasetType = 'train'):\n",
    "    if datasetType == 'test':\n",
    "        significantColumns = pickle.load(open(f\"../Data/Interim/{combinedName}SignificantNumericalCols.pkl\", 'rb'))\n",
    "    else:\n",
    "        scaler = StandardScaler()\n",
    "        numericalCols = list(numericalDF.columns)\n",
    "        numericalDF[numericalCols] = scaler.fit_transform(numericalDF[numericalCols])\n",
    "        significantColumns = []\n",
    "        allNumericalColumns = numericalDF.columns\n",
    "        for col in allNumericalColumns:\n",
    "            x = numericalDF[[col]].values.ravel()\n",
    "            p = spearmanr(x,y)[1]\n",
    "            if p < 0.05:\n",
    "                significantColumns.append(str(col))\n",
    "        pickle.dump(significantColumns, open(f\"../Data/Interim/{combinedName}SignificantNumericalCols.pkl\", 'wb'))\n",
    "    return numericalDF[significantColumns]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4982308f-ffe7-42fa-92d8-cef3210e4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOutliers(df,baseName):\n",
    "    numericalColList = pickle.load(open(f\"../Data/Interim/{baseName}SignificantNumericalCols.pkl\", 'rb'))\n",
    "    for col in numericalColList:\n",
    "        df = df.loc[(df[col] >= -3) & (df[col] <= 3)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb4fa2-052a-48a1-b42c-bfb2a07e7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeTestDF(categoricalDF,baseName):\n",
    "    ohe = pickle.load(open(f\"../Data/Interim/{baseName}OneHotEncoder.pkl\", 'rb'))\n",
    "    le = pickle.load(open(f\"../Data/Interim/{baseName}LabelEncoder.pkl\", 'rb'))\n",
    "    oheDF = ohe.transform(categoricalDF).fillna(0)\n",
    "    leDF = le.transform(categoricalDF)\n",
    "    return pd.concat([oheDF,leDF],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd9e5b-0bda-44c9-83df-1af42c146251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeDF(categoricalDF,baseName):\n",
    "    ohe = ce.OneHotEncoder(handle_unknown='ignore',return_df=True,use_cat_names=True)\n",
    "    le = ce.OrdinalEncoder(return_df=True)\n",
    "    oheDF = ohe.fit_transform(categoricalDF)\n",
    "    oheColumns = list(oheDF.columns)\n",
    "    pickle.dump(oheColumns, open(f\"../Data/Interim/{baseName}OheColumns.pkl\", 'wb'))\n",
    "    leDF = le.fit_transform(categoricalDF)\n",
    "    pickle.dump(ohe, open(f\"../Data/Interim/{baseName}OneHotEncoder.pkl\", 'wb'))\n",
    "    pickle.dump(le, open(f\"../Data/Interim/{baseName}LabelEncoder.pkl\", 'wb'))\n",
    "    return pd.concat([oheDF,leDF],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aab375-850c-4c6c-9095-968b5b160dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleTestDF(df,baseName):\n",
    "    scaler = pickle.load(open(f\"../Data/Interim/{baseName}Scaler.pkl\", 'rb'))\n",
    "    numericalCols = list(df.columns)\n",
    "    df[numericalCols] = scaler.transform(df[numericalCols])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5497a0e-3d31-4a3f-89fa-1ce633451545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleDF(df,baseName):\n",
    "    scaler = StandardScaler()\n",
    "    numericalCols = list(df.columns)\n",
    "    df[numericalCols] = scaler.fit_transform(df[numericalCols])\n",
    "    pickle.dump(scaler, open(f\"../Data/Interim/{baseName}Scaler.pkl\", 'wb'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2792db48-10a2-4bc0-9504-e92409545c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCategoricalColumns(df):\n",
    "    categoricalColumnIndecies = []\n",
    "    for i,col in enumerate(df.columns):\n",
    "        if np.issubdtype(df[col].dtype, np.number) == False:\n",
    "            categoricalColumnIndecies.append(i)\n",
    "    return categoricalColumnIndecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a340f-1654-42fb-80d6-45895c8a2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateDFBySubtype(df,baseName):\n",
    "    numericalCols = []\n",
    "    categoricalCols = []\n",
    "    for col in df.columns:\n",
    "        if np.issubdtype(df[col].dtype, np.number):\n",
    "            numericalCols.append(str(col))\n",
    "        else:\n",
    "            categoricalCols.append(str(col))\n",
    "    numericalDF = df[numericalCols]\n",
    "    categoricalDF = df[categoricalCols]\n",
    "    pickle.dump(numericalCols, open(f\"../Data/Interim/{baseName}NumericalCols.pkl\", 'wb'))\n",
    "    pickle.dump(categoricalCols, open(f\"../Data/Interim/{baseName}CategoricalCols.pkl\", 'wb'))\n",
    "    return numericalDF,categoricalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f2017c-a922-4e23-9eb7-8047a9fce903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceDataset(X,y,balanceType):\n",
    "    if balanceType == \"Under\":\n",
    "        balancer = RandomUnderSampler(random_state=51, replacement=True)\n",
    "    elif balanceType == \"Over\":\n",
    "        balancer = RandomOverSampler(random_state=51)\n",
    "    elif balanceType == \"NearMiss\":\n",
    "        balancer = NearMiss()\n",
    "    else: #default is SMOTE\n",
    "        categoricalVariables = [i for i,col in enumerate(X.columns) if not np.issubdtype(X[col].dtype, np.number)]\n",
    "        balancer = SMOTENC(categorical_features=categoricalVariables,random_state=51)\n",
    "    \n",
    "    if balanceType != \"NearMiss\":\n",
    "        return balancer.fit_resample(X, y)\n",
    "    else:\n",
    "        categoricalVariables = [col for col in X.columns if not np.issubdtype(X[col].dtype, np.number)]\n",
    "        encoder = ce.OneHotEncoder(cols=categoricalVariables)\n",
    "        X_encoded = encoder.fit_transform(X)\n",
    "        resampledX,resampledy = balancer.fit_resample(X_encoded, y)\n",
    "        return encoder.inverse_transform(resampledX),resampledy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae401a-8b55-4b80-863d-4f391ec1c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTestData(baseName):\n",
    "    originalTestDF = pd.read_csv(f\"../Data/Interim/{baseName}Test.csv\")\n",
    "    \n",
    "    numericalCols = pickle.load(open(f\"../Data/Interim/{baseName}NumericalCols.pkl\", 'rb'))\n",
    "    categoricalCols = pickle.load(open(f\"../Data/Interim/{baseName}CategoricalCols.pkl\", 'rb'))\n",
    "    \n",
    "    for balanceType in [\"Under\",\"Over\",\"Smote\",\"NearMiss\"]:\n",
    "        combinedName = baseName + balanceType\n",
    "        df = originalTestDF.copy()\n",
    "        y = df[[\"y\"]]\n",
    "        yArray = y.values.ravel()\n",
    "        df = df.drop(\"y\",axis = 1)\n",
    "        numericalDF = removeUnimportantNumericalColumns(df,yArray,combinedName,\"test\")\n",
    "        categoricalDF = removeUnimportantCategoricalColumns(df,yArray,combinedName,\"test\")\n",
    "        scaledDF = scaleTestDF(numericalDF,combinedName)\n",
    "        encodedDF = encodeTestDF(categoricalDF,combinedName)\n",
    "        finalDF = pd.concat([scaledDF,encodedDF],axis=1)\n",
    "        finalDF['y'] = yArray.reshape(-1,1)\n",
    "        finalDF.to_csv(f\"../Data/Processed/{combinedName}Test.csv\",index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b0d5b-1d3a-4e69-9ddf-74ab46b7bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTrainData(baseName):\n",
    "    unbalancedDF = pd.read_csv(f\"../Data/Interim/{baseName}Train.csv\")\n",
    "    originalY = unbalancedDF[[\"y\"]]\n",
    "    originalYArray = originalY.values.ravel()\n",
    "    originalX = unbalancedDF.drop(\"y\",axis = 1)\n",
    "    for balanceType in [\"Under\",\"Over\",\"Smote\",\"NearMiss\"]:\n",
    "        combinedName = baseName + balanceType\n",
    "        df,yArray = balanceDataset(originalX,originalYArray,balanceType)\n",
    "        numericalDF,categoricalDF = separateDFBySubtype(df,baseName)\n",
    "        numericalDF = removeUnimportantNumericalColumns(numericalDF,yArray,combinedName)\n",
    "        categoricalDF = removeUnimportantCategoricalColumns(categoricalDF,yArray,combinedName)\n",
    "        scaledDF = scaleDF(numericalDF,combinedName)\n",
    "        encodedDF = encodeDF(categoricalDF,combinedName)\n",
    "        preOutlierDF = pd.concat([scaledDF,encodedDF],axis=1)\n",
    "        preOutlierDF['y'] = yArray.reshape(-1,1)\n",
    "        finalDF = removeOutliers(preOutlierDF,combinedName)\n",
    "        finalDF.to_csv(f\"../Data/Processed/{combinedName}Train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df89ee1-1f5c-4455-a003-b1d215d277e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizeTargets(fileName):\n",
    "    df = pd.read_csv(fileName)\n",
    "    df.loc[df[\"y\"] == 'yes', \"y\"] = 1\n",
    "    df.loc[df[\"y\"] == 'no', \"y\"] = 0\n",
    "    df.to_csv(fileName,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396aa98c-f5d2-4c42-af8b-bc7d453f61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(baseName):\n",
    "    df = pd.read_csv(\"../Data/Raw/term-deposit-marketing-2020.csv\",index_col=[0])\n",
    "    y = df[[\"y\"]]\n",
    "    X = df.drop(\"y\",axis=1)\n",
    "    XTrain,XTest,yTrain,yTest = train_test_split(X, y, test_size=0.2,random_state=51)\n",
    "    TermDepositTrain = XTrain.copy()\n",
    "    TermDepositTrain['y'] = yTrain\n",
    "    TermDepositTrain.to_csv(f'../Data/Interim/{baseName}Train.csv',index=False)\n",
    "    TermDepositTest = XTest.copy()\n",
    "    TermDepositTest['y'] = yTest\n",
    "    TermDepositTest.to_csv(f'../Data/Interim/{baseName}Test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13ee52-9cab-4a59-93cf-c622325299e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    np.random.seed(51)\n",
    "    baseName = \"TermDeposit\"\n",
    "    if exists(f\"../Data/Interim/{baseName}Train.csv\") == False:\n",
    "        splitData(baseName)\n",
    "        binarizeTargets(f\"../Data/Interim/{baseName}Train.csv\")\n",
    "        binarizeTargets(f\"../Data/Interim/{baseName}Test.csv\")\n",
    "    processTrainData(baseName)\n",
    "    processTestData(baseName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1573bea1-4b48-44b4-99d4-1f454ce6a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
