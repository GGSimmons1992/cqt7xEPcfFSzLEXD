{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e5ee8-6ec3-43ee-be7d-be11fc050347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "from os.path import exists\n",
    "import pickle\n",
    "#import json\n",
    "#import scipy.stats as stats\n",
    "#import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import seaborn as sb\n",
    "#from sklearn.ensemble import RandomForestClassifier as rf\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#import sklearn.linear_model as lm\n",
    "#from sklearn.tree import DecisionTreeClassifier as tree\n",
    "#from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "#from xgboost import XGBClassifier as xgb\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.naive_bayes import GaussianNB as gnb\n",
    "#from sklearn.ensemble import VotingClassifier\n",
    "#import sklearn.model_selection as ms\n",
    "#import sklearn.metrics as sm\n",
    "#import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4982308f-ffe7-42fa-92d8-cef3210e4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOutliers(df,baseName):\n",
    "    numericalColList = pickle.load(open(f\"../Data/Interim/{baseName}NumericalCols.pkl\", 'rb'))\n",
    "    for col in numericalColList:\n",
    "        df = df.loc[(df[col] >= -3) & (df[col] <= 3)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb4fa2-052a-48a1-b42c-bfb2a07e7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeTestDF(categoricalDF,baseName):\n",
    "    ohe = pickle.load(open(f\"../Data/Interim/{baseName}OneHotEncoder.pkl\", 'rb'))\n",
    "    le = pickle.load(open(f\"../Data/Interim/{baseName}LabelEncoder.pkl\", 'rb'))\n",
    "    oheDF = ohe.transform(categoricalDF).fillna(0)\n",
    "    leDF = le.transform(categoricalDF)\n",
    "    return pd.concat([oheDF,leDF],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd9e5b-0bda-44c9-83df-1af42c146251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeDF(categoricalDF,baseName):\n",
    "    ohe = ce.OneHotEncoder(handle_unknown='ignore',return_df=True,use_cat_names=True)\n",
    "    le = ce.OrdinalEncoder(return_df=True)\n",
    "    oheDF = ohe.fit_transform(categoricalDF)\n",
    "    oheColumns = list(oheDF.columns)\n",
    "    pickle.dump(oheColumns, open(f\"../Data/Interim/{baseName}OheColumns.pkl\", 'wb'))\n",
    "    leDF = le.fit_transform(categoricalDF)\n",
    "    pickle.dump(ohe, open(f\"../Data/Interim/{baseName}OneHotEncoder.pkl\", 'wb'))\n",
    "    pickle.dump(le, open(f\"../Data/Interim/{baseName}LabelEncoder.pkl\", 'wb'))\n",
    "    return pd.concat([oheDF,leDF],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aab375-850c-4c6c-9095-968b5b160dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleTestDF(df,baseName):\n",
    "    scaler = pickle.load(open(f\"../Data/Interim/{baseName}Scaler.pkl\", 'rb'))\n",
    "    numericalCols = list(df.columns)\n",
    "    df[numericalCols] = scaler.transform(df[numericalCols])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5497a0e-3d31-4a3f-89fa-1ce633451545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleDF(df,baseName):\n",
    "    scaler = StandardScaler()\n",
    "    numericalCols = list(df.columns)\n",
    "    df[numericalCols] = scaler.fit_transform(df[numericalCols])\n",
    "    pickle.dump(scaler, open(f\"../Data/Interim/{baseName}Scaler.pkl\", 'wb'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a340f-1654-42fb-80d6-45895c8a2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateDFBySubtype(df,baseName):\n",
    "    numericalCols = []\n",
    "    categoricalCols = []\n",
    "    for col in df.columns:\n",
    "        if np.issubdtype(df[col].dtype, np.number):\n",
    "            numericalCols.append(str(col))\n",
    "        else:\n",
    "            categoricalCols.append(str(col))\n",
    "    numericalDF = df[numericalCols]\n",
    "    categoricalDF = df[categoricalCols]\n",
    "    pickle.dump(numericalCols, open(f\"../Data/Interim/{baseName}NumericalCols.pkl\", 'wb'))\n",
    "    pickle.dump(categoricalCols, open(f\"../Data/Interim/{baseName}CategoricalCols.pkl\", 'wb'))\n",
    "    return numericalDF,categoricalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae401a-8b55-4b80-863d-4f391ec1c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTestData(baseName):\n",
    "    df = pd.read_csv(f\"../Data/Interim/{baseName}Test.csv\")\n",
    "    numericalCols = pickle.load(open(f\"../Data/Interim/{baseName}NumericalCols.pkl\", 'rb'))\n",
    "    categoricalCols = pickle.load(open(f\"../Data/Interim/{baseName}CategoricalCols.pkl\", 'rb'))\n",
    "    y = df[[\"y\"]]\n",
    "    df = df.drop(\"y\",axis = 1)\n",
    "    for balanceType in [\"Under\",\"Over\"]:\n",
    "        combinedName = baseName + balanceType\n",
    "        numericalDF,categoricalDF = df[numericalCols],df[categoricalCols]\n",
    "        scaledDF = scaleTestDF(numericalDF,combinedName)\n",
    "        encodedDF = encodeTestDF(categoricalDF,combinedName)\n",
    "        finalDF = pd.concat([scaledDF,encodedDF,y],axis=1)\n",
    "        finalDF.to_csv(f\"../Data/Processed/{combinedName}Test.csv\",index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b0d5b-1d3a-4e69-9ddf-74ab46b7bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTrainData(baseName):\n",
    "    unbalancedDF = pd.read_csv(f\"../Data/Interim/{baseName}Train.csv\")\n",
    "    unbalancedZeros = unbalancedDF[unbalancedDF[\"y\"] == 0]\n",
    "    unbalancedOnes = unbalancedDF[unbalancedDF[\"y\"] == 1]\n",
    "    \n",
    "    for balanceType in [\"Under\",\"Over\"]:\n",
    "        combinedName = baseName + balanceType\n",
    "        if balanceType == \"Under\":\n",
    "            balancedZeros = unbalancedZeros.sample(unbalancedOnes.shape[0],random_state=51)\n",
    "            balancedOnes = unbalancedOnes\n",
    "        else:\n",
    "            balancedZeros = unbalancedZeros\n",
    "            balancedOnes = unbalancedOnes.sample(unbalancedZeros.shape[0],replace=True,random_state=51)\n",
    "        df = pd.concat([balancedZeros,balancedOnes],axis=0)\n",
    "        y = df[[\"y\"]]\n",
    "        df = df.drop(\"y\",axis = 1)\n",
    "        numericalDF,categoricalDF = separateDFBySubtype(df,baseName)\n",
    "        scaledDF = scaleDF(numericalDF,combinedName)\n",
    "        encodedDF = encodeDF(categoricalDF,combinedName)\n",
    "        preOutlierDF = pd.concat([scaledDF,encodedDF,y],axis=1)\n",
    "        finalDF = removeOutliers(preOutlierDF,baseName)\n",
    "        finalDF.to_csv(f\"../Data/Processed/{combinedName}Train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df89ee1-1f5c-4455-a003-b1d215d277e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizeTargets(fileName):\n",
    "    df = pd.read_csv(fileName)\n",
    "    df.loc[df[\"y\"] == 'yes', \"y\"] = 1\n",
    "    df.loc[df[\"y\"] == 'no', \"y\"] = 0\n",
    "    df.to_csv(fileName,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396aa98c-f5d2-4c42-af8b-bc7d453f61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(baseName):\n",
    "    df = pd.read_csv(\"../Data/Raw/term-deposit-marketing-2020.csv\",index_col=[0])\n",
    "    y = df[[\"y\"]]\n",
    "    X = df.drop(\"y\",axis=1)\n",
    "    XTrain,XTest,yTrain,yTest = train_test_split(X, y, test_size=0.2,random_state=51)\n",
    "    TermDepositTrain = XTrain.copy()\n",
    "    TermDepositTrain['y'] = yTrain\n",
    "    TermDepositTrain.to_csv(f'../Data/Interim/{baseName}Train.csv',index=False)\n",
    "    TermDepositTest = XTest.copy()\n",
    "    TermDepositTest['y'] = yTest\n",
    "    TermDepositTest.to_csv(f'../Data/Interim/{baseName}Test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13ee52-9cab-4a59-93cf-c622325299e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    np.random.seed(51)\n",
    "    baseName = \"TermDeposit\"\n",
    "    if exists(f\"../Data/Interim/{baseName}Train.csv\") == False:\n",
    "        splitData(baseName)\n",
    "        binarizeTargets(f\"../Data/Interim/{baseName}Train.csv\")\n",
    "        binarizeTargets(f\"../Data/Interim/{baseName}Test.csv\")\n",
    "    processTrainData(baseName)\n",
    "    processTestData(baseName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1573bea1-4b48-44b4-99d4-1f454ce6a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e6367-89bb-41c7-9a7d-5ee14e4da203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
